{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa02e65",
   "metadata": {},
   "source": [
    "## Simple Burrows Wheeler Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f5e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = input()\n",
    "words = list(a)\n",
    "bwt = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e76af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(words)):\n",
    "    word = a[-1] + a[:-1]\n",
    "    new = ''.join(word)\n",
    "    a = new\n",
    "    bwt.append(new)\n",
    "    i += 1\n",
    "print(bwt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9bd183",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = sorted(bwt)\n",
    "print(sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e52767",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for i in range(len(words)):\n",
    "    element = sort[i]\n",
    "    last = element[-1]\n",
    "    i = i + 1\n",
    "    output.append(last)\n",
    "print(\"\".join(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05053714",
   "metadata": {},
   "source": [
    "## Suffix Array BWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "70a9c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "def suffix_array(string):\n",
    "    return(list(sorted(range(len(string)), key=lambda i:string[i:])))\n",
    "\n",
    "def bwt_from_suffix(string, s_array=None):\n",
    "    if s_array is None:\n",
    "        s_array = suffix_array(string)\n",
    "    return(\"\".join(string[idx - 1] for idx in s_array))\n",
    "\n",
    "\n",
    "def lf_mapping(bwt, letters=None):\n",
    "    if letters is None:\n",
    "        letters = set(bwt)\n",
    "        \n",
    "    result = {letter:[0] for letter in letters}\n",
    "    result[bwt[0]] = [1]\n",
    "    for letter in bwt[1:]:\n",
    "        for i, j in result.items():\n",
    "            j.append(j[-1] + (i == letter))\n",
    "    return(result)\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def count_occurences(string, letters=None):\n",
    "    count = 0\n",
    "    result = {}\n",
    "    \n",
    "    if letters is None:\n",
    "        letters = set(s)\n",
    "        \n",
    "    c = Counter(string)\n",
    "    \n",
    "    for letter in sorted(letters):\n",
    "        result[letter] = count\n",
    "        count += c[letter]\n",
    "    return result\n",
    "\n",
    "\n",
    "def update(begin, end, letter, lf_map, counts, string_length):\n",
    "    beginning = counts[letter] + lf_map[letter][begin - 1] + 1\n",
    "    ending = counts[letter] + lf_map[letter][end]\n",
    "    return(beginning,ending)\n",
    "\n",
    "\n",
    "\n",
    "def generate_all(input_string, s_array=None, eos=\"$\"):\n",
    "    letters = set(input_string)\n",
    "    try:\n",
    "        assert eos not in letters\n",
    "    \n",
    "        counts = count_occurences(input_string, letters)\n",
    "\n",
    "        input_string = \"\".join([input_string, eos])\n",
    "        if s_array is None:\n",
    "            s_array = suffix_array(input_string)\n",
    "        bwt = bwt_from_suffix(input_string, s_array)\n",
    "        lf_map = lf_mapping(bwt, letters | set([eos]))\n",
    "\n",
    "        for i, j in lf_map.items():\n",
    "            j.extend([j[-1], 0]) # for when pointers go off the edges\n",
    "\n",
    "        return letters, bwt, lf_map, counts, s_array\n",
    "\n",
    "    except:\n",
    "        print(\"End of string character found in text, deleted EOS from input string\")\n",
    "        input_string = input_string.replace(eos, \"\")\n",
    "        letters = set(input_string)\n",
    "        counts = count_occurences(input_string, letters)\n",
    "\n",
    "        input_string = \"\".join([input_string, eos])\n",
    "        if s_array is None:\n",
    "            s_array = suffix_array(input_string)\n",
    "        bwt = bwt_from_suffix(input_string, s_array)\n",
    "        lf_map = lf_mapping(bwt, letters | set([eos]))\n",
    "\n",
    "        for i, j in lf_map.items():\n",
    "            j.extend([j[-1], 0]) # for when pointers go off the edges\n",
    "\n",
    "        return letters, bwt, lf_map, counts, s_array\n",
    "\n",
    "    \n",
    "def find(search_string, input_string, mismatches=0, bwt_data=None, s_array=None):\n",
    "    \n",
    "    results = []\n",
    "     \n",
    "    if len(search_string) == 0:\n",
    "        return(\"Empty Query String\")\n",
    "    if bwt_data is None:\n",
    "        bwt_data = generate_all(input_string, s_array=s_array)\n",
    "    \n",
    "    letters, bwt, lf_map, count, s_array = bwt_data\n",
    "    \n",
    "    if len(letters) == 0:\n",
    "        return(\"Empty Search String\")\n",
    "\n",
    "    if not set(search_string) <= letters:\n",
    "        return []\n",
    "\n",
    "    length = len(bwt)\n",
    "    \n",
    "\n",
    "    class Fuzzy(object):\n",
    "        def __init__(self, **kwargs):\n",
    "            self.__dict__.update(kwargs)\n",
    "\n",
    "    fuz = [Fuzzy(search_string=search_string, begin=0, end=len(bwt) - 1,\n",
    "                        mismatches=mismatches)]\n",
    "\n",
    "    while len(fuz) > 0:\n",
    "        p = fuz.pop()\n",
    "        search_string = p.search_string[:-1]\n",
    "        last = p.search_string[-1]\n",
    "        all_letters = [last] if p.mismatches == 0 else letters\n",
    "        for letter in all_letters:\n",
    "            begin, end = update(p.begin, p.end, letter, lf_map, count, length)\n",
    "            if begin <= end:\n",
    "                if len(search_string) == 0:\n",
    "                    results.extend(s_array[begin : end + 1])\n",
    "                else:\n",
    "                    miss = p.mismatches\n",
    "                    if letter != last:\n",
    "                        miss = max(0, p.mismatches - 1)\n",
    "                    fuz.append(Fuzzy(search_string=search_string, begin=begin,\n",
    "                                            end=end, mismatches=miss))\n",
    "    return sorted(set(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be1a83f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e$lppa'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EOS = \"$\"\n",
    "bwt_from_suffix(\"apple$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1e0b019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'a', 'e', 'l', 'p'},\n",
       " 'e$lppa',\n",
       " {'e': [1, 1, 1, 1, 1, 1, 1, 0],\n",
       "  'p': [0, 0, 0, 1, 2, 2, 2, 0],\n",
       "  'l': [0, 0, 1, 1, 1, 1, 1, 0],\n",
       "  '$': [0, 1, 1, 1, 1, 1, 1, 0],\n",
       "  'a': [0, 0, 0, 0, 0, 1, 1, 0]},\n",
       " {'a': 0, 'e': 1, 'l': 2, 'p': 3},\n",
       " [5, 0, 4, 3, 2, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_all(\"apple\")\n",
    "## unique letters \n",
    "## BWT\n",
    "## LF Map\n",
    "## Character Count in unique letters\n",
    "## Suffix array numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0aaf567d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find(\"ape\", 'apple', mismatches=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bc47bd",
   "metadata": {},
   "source": [
    "## Alice in Wonderland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9a479b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Exact Matches: 3\n",
      "Number of Exact Matches: 0\n",
      "Number of Fuzzy Matches: 5\n"
     ]
    }
   ],
   "source": [
    "#%%timeit  ## ~2.44 s Â± 377\n",
    "# Alice in Wonderland Starting from Chapter 8 \n",
    "import urllib3\n",
    "url = 'https://www.gutenberg.org/files/11/11-0.txt'\n",
    "http = urllib3.PoolManager()\n",
    "text = http.urlopen(\"GET\", url).data.decode()\n",
    "chapters = text.split(\"THE END\")[0].split(\"CHAPTER VIII\")[2]\n",
    "\n",
    "\n",
    "## 61235 Characters | 27432 Words | 3762 Lines\n",
    "#characters = len(text)\n",
    "#words = len(text.split(\" \"))\n",
    "#lines = len(text.split(\"\\n\"))\n",
    "\n",
    "\n",
    "\n",
    "bwt_data = generate_all(chapters)\n",
    "\n",
    "## 3 instances of \"Off with her head\"\n",
    "print(\"Number of Exact Matches: \"+ str(len(find('Off with her head', chapters, mismatches=0, bwt_data=bwt_data))))\n",
    "\n",
    "## 0 instances of \"off with her head\" CASE SENSITIVE\n",
    "print(\"Number of Exact Matches: \"+ str(len(find('off with her head', chapters, mismatches=0, bwt_data=bwt_data))))\n",
    "\n",
    "### Mismatches = 2\n",
    "## 5 instances of \"Off with her/his head\"\n",
    "print(\"Number of Fuzzy Matches: \"+ str(len(find('Off with her head', chapters, mismatches=2, bwt_data=bwt_data))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df49f491",
   "metadata": {},
   "source": [
    "### String based control (default python string search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4d821bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713 ms Â± 39.2 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "[n for n in range(len(chapters)) if chapters.find(\"Off with her head\", n) == n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a97c74",
   "metadata": {},
   "source": [
    "### Exact matching time!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8e3e097b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.4 Âµs Â± 1.34 Âµs per loop (mean Â± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "find('Off with her head', chapters, mismatches=0, bwt_data=bwt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5b2084",
   "metadata": {},
   "source": [
    "### Fuzzy matching time!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e3c16097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.34 ms Â± 440 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "find('Off with her head', chapters, mismatches=2, bwt_data=bwt_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
